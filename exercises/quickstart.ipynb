{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quickstart\n",
    "\n",
    "This notebook is just to make sure that everything works. Firstly, create a file called `.env` in this folder, and add the following content, obviously with your values. There are two ways to authenticate: using a token or using the Azure CLI (AAD authentication). The Azure CLI is the recommended way.\n",
    "\n",
    "```\n",
    "OPENAI_API_KEY=xxxxxx\n",
    "OPENAI_API_BASE=https://xxxxxxx.openai.azure.com/\n",
    "```\n",
    "\n",
    "When authenticating using Azure CLI + Azure AD, open a terminal and run the following command: `az login --use-device-code`. This will open a browser window where you can authenticate. After authentication, use Option 1 code to run and you are good to go.\n",
    "\n",
    "*(You could as well run the following command to get the token: `az account get-access-token --resource https://management.core.windows.net/ --query accessToken -o tsv`. Copy the token and add it to the `.env` file and then use the token to authenticate.)*\n",
    "\n",
    "> **ðŸ”” Please note that in all following notebooks you will need to set the authentication method accordingly!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tiktoken\n",
    "import openai\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from azure.identity import DefaultAzureCredential\n",
    "#from openai.embeddings_utils import cosine_similarity\n",
    "from tenacity import retry, wait_random_exponential, stop_after_attempt\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Option 1 - Use Azure AD authentication with az cli (use az login in terminal)\n",
    "#default_credential = DefaultAzureCredential()\n",
    "#token = default_credential.get_token(\"https://cognitiveservices.azure.com/.default\")\n",
    "#openai.api_type = \"azure_ad\"\n",
    "#openai.api_base = os.environ.get(\"OPENAI_API_BASE\")\n",
    "#openai.api_key = token.token\n",
    "#openai.api_version = \"2022-12-01\"\n",
    "\n",
    "# Option 2 - Using Access Key\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_base = os.environ.get(\"OPENAI_API_BASE\")\n",
    "openai.api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "openai.api_version = \"2022-12-01\"\n",
    "\n",
    "# Define embedding model and encoding\n",
    "EMBEDDING_MODEL = 'text-embedding-ada-002'\n",
    "COMPLETION_MODEL = 'text-davinci-003'\n",
    "encoding = tiktoken.get_encoding('cl100k_base')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test if completitions work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Who's there?\n",
      "\n",
      "Boo.\n",
      "\n",
      "Boo who?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = openai.Completion.create(engine=\"text-davinci-003\",\n",
    "                                    prompt=\"Knock knock.\",\n",
    "                                    temperature=0)\n",
    "print(response.choices[0].text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do it in a streaming fashion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. \"It Doesnâ€™t Get Any Sweeter Than This!\" \n",
      "2. \"The Coolest Treat Around!\" \n",
      "3. \"Pile It High and Enjoy!\" \n",
      "4. \"Lickin' Good Fun!\" \n",
      "5. \"The One-Stop Sweet Shop!\" \n",
      "6. \"So Delicious, You'll Want Seconds!\" \n",
      "7. \"Taste the Flavour!\"\n",
      "8. \"Let's Scoop Up Some Fun!\" \n",
      "9. \"Make Your Sweet Dreams Come True!\" \n",
      "10. \"The Taste That Thrills!\""
     ]
    }
   ],
   "source": [
    "import sys\n",
    "for resp in openai.Completion.create(engine='text-davinci-003', prompt='Give me 10 taglines for an ice cream shop', max_tokens=512, stream=True):\n",
    "    sys.stdout.write(resp.choices[0].text)\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test if embeddings work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "MissingDependencyError",
     "evalue": "\n\nOpenAI error: \n\n    missing `numpy` \n\nThis feature requires additional dependencies:\n\n    $ pip install openai[datalib]\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMissingDependencyError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m e \u001b[39m=\u001b[39m openai\u001b[39m.\u001b[39;49mEmbedding\u001b[39m.\u001b[39;49mcreate(\u001b[39minput\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mHello World!\u001b[39;49m\u001b[39m\"\u001b[39;49m, engine\u001b[39m=\u001b[39;49mEMBEDDING_MODEL)[\u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39membedding\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m      2\u001b[0m \u001b[39mprint\u001b[39m(e)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/openai/api_resources/embedding.py:42\u001b[0m, in \u001b[0;36mEmbedding.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m response\u001b[39m.\u001b[39mdata:\n\u001b[1;32m     39\u001b[0m \n\u001b[1;32m     40\u001b[0m         \u001b[39m# If an engine isn't using this optimization, don't do anything\u001b[39;00m\n\u001b[1;32m     41\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mtype\u001b[39m(data[\u001b[39m\"\u001b[39m\u001b[39membedding\u001b[39m\u001b[39m\"\u001b[39m]) \u001b[39m==\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[0;32m---> 42\u001b[0m             assert_has_numpy()\n\u001b[1;32m     43\u001b[0m             data[\u001b[39m\"\u001b[39m\u001b[39membedding\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mfrombuffer(\n\u001b[1;32m     44\u001b[0m                 base64\u001b[39m.\u001b[39mb64decode(data[\u001b[39m\"\u001b[39m\u001b[39membedding\u001b[39m\u001b[39m\"\u001b[39m]), dtype\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mfloat32\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     45\u001b[0m             )\u001b[39m.\u001b[39mtolist()\n\u001b[1;32m     47\u001b[0m \u001b[39mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/openai/datalib.py:51\u001b[0m, in \u001b[0;36massert_has_numpy\u001b[0;34m()\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39massert_has_numpy\u001b[39m():\n\u001b[1;32m     50\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m HAS_NUMPY:\n\u001b[0;32m---> 51\u001b[0m         \u001b[39mraise\u001b[39;00m MissingDependencyError(NUMPY_INSTRUCTIONS)\n",
      "\u001b[0;31mMissingDependencyError\u001b[0m: \n\nOpenAI error: \n\n    missing `numpy` \n\nThis feature requires additional dependencies:\n\n    $ pip install openai[datalib]\n\n"
     ]
    }
   ],
   "source": [
    "e = openai.Embedding.create(input=\"Hello World!\", engine=EMBEDDING_MODEL)[\"data\"][0][\"embedding\"]\n",
    "print(e)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test if tokenizer works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9906, 1917, 0]\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "tokens = encoding.encode(\"Hello world!\")\n",
    "print(tokens)\n",
    "print(len(tokens))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also let's check if LangChain works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USING API_BASE: \n",
      "https://genaihackathon.openai.azure.com/\n",
      "\n",
      "\n",
      "Q: What did the baby corn say to the mama corn?\n",
      "A: Where's my pop corn?\n"
     ]
    },
    {
     "ename": "MissingDependencyError",
     "evalue": "\n\nOpenAI error: \n\n    missing `numpy` \n\nThis feature requires additional dependencies:\n\n    $ pip install openai[datalib]\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMissingDependencyError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 26\u001b[0m\n\u001b[1;32m     23\u001b[0m text \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mThis is a test document.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     25\u001b[0m \u001b[39m# Embed a single document\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m query_result \u001b[39m=\u001b[39m embeddings\u001b[39m.\u001b[39;49membed_query(text)\n\u001b[1;32m     27\u001b[0m \u001b[39mprint\u001b[39m(query_result)\n\u001b[1;32m     29\u001b[0m \u001b[39m# Embed multiple documents at once\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/langchain/embeddings/openai.py:297\u001b[0m, in \u001b[0;36mOpenAIEmbeddings.embed_query\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39membed_query\u001b[39m(\u001b[39mself\u001b[39m, text: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[\u001b[39mfloat\u001b[39m]:\n\u001b[1;32m    289\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Call out to OpenAI's embedding endpoint for embedding query text.\u001b[39;00m\n\u001b[1;32m    290\u001b[0m \n\u001b[1;32m    291\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[39m        Embedding for the text.\u001b[39;00m\n\u001b[1;32m    296\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 297\u001b[0m     embedding \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_embedding_func(text, engine\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mquery_model_name)\n\u001b[1;32m    298\u001b[0m     \u001b[39mreturn\u001b[39;00m embedding\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/langchain/embeddings/openai.py:252\u001b[0m, in \u001b[0;36mOpenAIEmbeddings._embedding_func\u001b[0;34m(self, text, engine)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[39m# handle large input text\u001b[39;00m\n\u001b[1;32m    251\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membedding_ctx_length \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 252\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_len_safe_embeddings([text], engine\u001b[39m=\u001b[39;49mengine)[\u001b[39m0\u001b[39m]\n\u001b[1;32m    253\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    254\u001b[0m     \u001b[39m# replace newlines, which can negatively affect performance.\u001b[39;00m\n\u001b[1;32m    255\u001b[0m     text \u001b[39m=\u001b[39m text\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/langchain/embeddings/openai.py:222\u001b[0m, in \u001b[0;36mOpenAIEmbeddings._get_len_safe_embeddings\u001b[0;34m(self, texts, engine, chunk_size)\u001b[0m\n\u001b[1;32m    220\u001b[0m _chunk_size \u001b[39m=\u001b[39m chunk_size \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchunk_size\n\u001b[1;32m    221\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, \u001b[39mlen\u001b[39m(tokens), _chunk_size):\n\u001b[0;32m--> 222\u001b[0m     response \u001b[39m=\u001b[39m embed_with_retry(\n\u001b[1;32m    223\u001b[0m         \u001b[39mself\u001b[39;49m,\n\u001b[1;32m    224\u001b[0m         \u001b[39minput\u001b[39;49m\u001b[39m=\u001b[39;49mtokens[i : i \u001b[39m+\u001b[39;49m _chunk_size],\n\u001b[1;32m    225\u001b[0m         engine\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdocument_model_name,\n\u001b[1;32m    226\u001b[0m     )\n\u001b[1;32m    227\u001b[0m     batched_embeddings \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m [r[\u001b[39m\"\u001b[39m\u001b[39membedding\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39mfor\u001b[39;00m r \u001b[39min\u001b[39;00m response[\u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m]]\n\u001b[1;32m    229\u001b[0m results: List[List[List[\u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m [[] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(texts))]\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/langchain/embeddings/openai.py:63\u001b[0m, in \u001b[0;36membed_with_retry\u001b[0;34m(embeddings, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[39m@retry_decorator\u001b[39m\n\u001b[1;32m     60\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_embed_with_retry\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m     61\u001b[0m     \u001b[39mreturn\u001b[39;00m embeddings\u001b[39m.\u001b[39mclient\u001b[39m.\u001b[39mcreate(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m---> 63\u001b[0m \u001b[39mreturn\u001b[39;00m _embed_with_retry(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/tenacity/__init__.py:289\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(f)\n\u001b[1;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped_f\u001b[39m(\u001b[39m*\u001b[39margs: t\u001b[39m.\u001b[39mAny, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw: t\u001b[39m.\u001b[39mAny) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m t\u001b[39m.\u001b[39mAny:\n\u001b[0;32m--> 289\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(f, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/tenacity/__init__.py:379\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    377\u001b[0m retry_state \u001b[39m=\u001b[39m RetryCallState(retry_object\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m, fn\u001b[39m=\u001b[39mfn, args\u001b[39m=\u001b[39margs, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[1;32m    378\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 379\u001b[0m     do \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miter(retry_state\u001b[39m=\u001b[39;49mretry_state)\n\u001b[1;32m    380\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    381\u001b[0m         \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/tenacity/__init__.py:314\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    312\u001b[0m is_explicit_retry \u001b[39m=\u001b[39m fut\u001b[39m.\u001b[39mfailed \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(fut\u001b[39m.\u001b[39mexception(), TryAgain)\n\u001b[1;32m    313\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (is_explicit_retry \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mretry(retry_state)):\n\u001b[0;32m--> 314\u001b[0m     \u001b[39mreturn\u001b[39;00m fut\u001b[39m.\u001b[39;49mresult()\n\u001b[1;32m    316\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mafter \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    317\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mafter(retry_state)\n",
      "File \u001b[0;32m/usr/lib/python3.9/concurrent/futures/_base.py:433\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    431\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    432\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[0;32m--> 433\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__get_result()\n\u001b[1;32m    435\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_condition\u001b[39m.\u001b[39mwait(timeout)\n\u001b[1;32m    437\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m/usr/lib/python3.9/concurrent/futures/_base.py:389\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__get_result\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    388\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception:\n\u001b[0;32m--> 389\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[1;32m    390\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    391\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_result\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/tenacity/__init__.py:382\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    381\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 382\u001b[0m         result \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    383\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m:  \u001b[39m# noqa: B902\u001b[39;00m\n\u001b[1;32m    384\u001b[0m         retry_state\u001b[39m.\u001b[39mset_exception(sys\u001b[39m.\u001b[39mexc_info())  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/langchain/embeddings/openai.py:61\u001b[0m, in \u001b[0;36membed_with_retry.<locals>._embed_with_retry\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[39m@retry_decorator\u001b[39m\n\u001b[1;32m     60\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_embed_with_retry\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[0;32m---> 61\u001b[0m     \u001b[39mreturn\u001b[39;00m embeddings\u001b[39m.\u001b[39;49mclient\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/openai/api_resources/embedding.py:42\u001b[0m, in \u001b[0;36mEmbedding.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m response\u001b[39m.\u001b[39mdata:\n\u001b[1;32m     39\u001b[0m \n\u001b[1;32m     40\u001b[0m         \u001b[39m# If an engine isn't using this optimization, don't do anything\u001b[39;00m\n\u001b[1;32m     41\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mtype\u001b[39m(data[\u001b[39m\"\u001b[39m\u001b[39membedding\u001b[39m\u001b[39m\"\u001b[39m]) \u001b[39m==\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[0;32m---> 42\u001b[0m             assert_has_numpy()\n\u001b[1;32m     43\u001b[0m             data[\u001b[39m\"\u001b[39m\u001b[39membedding\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mfrombuffer(\n\u001b[1;32m     44\u001b[0m                 base64\u001b[39m.\u001b[39mb64decode(data[\u001b[39m\"\u001b[39m\u001b[39membedding\u001b[39m\u001b[39m\"\u001b[39m]), dtype\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mfloat32\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     45\u001b[0m             )\u001b[39m.\u001b[39mtolist()\n\u001b[1;32m     47\u001b[0m \u001b[39mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/openai/datalib.py:51\u001b[0m, in \u001b[0;36massert_has_numpy\u001b[0;34m()\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39massert_has_numpy\u001b[39m():\n\u001b[1;32m     50\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m HAS_NUMPY:\n\u001b[0;32m---> 51\u001b[0m         \u001b[39mraise\u001b[39;00m MissingDependencyError(NUMPY_INSTRUCTIONS)\n",
      "\u001b[0;31mMissingDependencyError\u001b[0m: \n\nOpenAI error: \n\n    missing `numpy` \n\nThis feature requires additional dependencies:\n\n    $ pip install openai[datalib]\n\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "from langchain.llms import AzureOpenAI\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Configure Azure OpenAI Service API\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_version = \"2022-12-01\"\n",
    "openai.api_base = os.getenv('OPENAI_API_BASE')\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Create a completion\n",
    "llm = AzureOpenAI(deployment_name=\"text-davinci-003\")\n",
    "joke = llm(\"Tell me a dad joke\")\n",
    "print(joke)\n",
    "\n",
    "# Create embeddings\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\", chunk_size=1)\n",
    "text = \"This is a test document.\"\n",
    "\n",
    "# Embed a single document\n",
    "query_result = embeddings.embed_query(text)\n",
    "print(query_result)\n",
    "\n",
    "# Embed multiple documents at once\n",
    "doc_result = embeddings.embed_documents([text, text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai-qna-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c4ee1bbf3137c7ea9420c4fd488a55642063e5739fe2a7286130d9ba47405b69"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
